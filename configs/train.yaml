exp_name: 'pretrain'
device: "cuda"
seed: 20
train_jsons: [
  'data/json_files/AudioSet/train.json',
  'data/json_files/Clotho/train.json',
]
val_jsons: [
  "data/json_files/AudioSet/val.json",
]
blacklist: ""
# dataset == 'AudioCaps': sampling_rate = 32000
# dataset == 'Clotho': sampling_rate = 44100
# 48000 for CLAP
# 32000 for HTSAT
audio_args:
  sr: 48000
  n_fft: 1024
  hop_length: 320
  f_min: 50
  f_max: 14000
  n_mels: 64
  max_length: 10
  mono: True

data_args:
  dataset: "Clotho"
  batch_size: 8
  num_workers: 4

model_args:
  name: "CLAP2LLAMA"
  freeze_am: True
  freeze_lm: False
  checkpoint_path: "./pretrained_models/pretrained_MLP/"

# lr from wavcaps, linear scale lr
optim_args:
  lr: 2.5e-5
  betas: [0.9, 0.99]
  eps: 1e-8
  momentum: 0.9
  gamma: 0.1
  weight_decay: 0.01

training:
  warmup_epochs: 2
  epochs: 10
  clip_grad: 2
  output_path: "./finetuned_models/audio_caption/"
  eval: False
  use_retrieval: True

index_args:
  index_save_path: "./data/index"
  index_types: ["audio", "text"]
  top_k: 2
  query_mode: "audio2audio"
