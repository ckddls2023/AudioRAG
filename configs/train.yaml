exp_name: 'train'
seed: 20

train_jsons: [
  'data/json_files/AudioSet/train.json',
  'data/json_files/Clotho/train.json',
]
val_jsons: [
  "data/json_files/AudioSet/val.json",
  #"data/json_files/Clotho/val.json",
]
blacklist: ""
# dataset == 'AudioCaps': sampling_rate = 32000
# dataset == 'Clotho': sampling_rate = 44100
# 48000 for CLAP
# 32000 for HTSAT
audio_args:
  sr: 48000
  n_fft: 1024
  hop_length: 320
  f_min: 50
  f_max: 14000
  n_mels: 64
  max_length: 10
  mono: True

data_args:
  dataset: "Clotho"
  global_batch_size: 256
  batch_size: 4
  num_workers: 16

model_args:
  name: "CLAP2LLAMA"
  freeze_am: True
  #unfreeze_am: ['model.audio_branch.layers.3.blocks.1']
  unfreeze_am: []
  freeze_lm: False
  #checkpoint_path: "./finetuned_models/audio2audio_MLP/"
  #checkpoint_path: "./finetuned_models/frame2audio_MLP/"
  checkpoint_path: "./finetuned_models/audio2text_MLP/"
  #checkpoint_path: "./finetuned_models/finetuned_MLP/"
  #checkpoint_path: "./pretrained_models/pretrained_MLP/"
  encoder:
    model_name: "CLAPAudioEncoder"
    pretrained: True
    freeze: True
    spec_augment: True
    select_feature: "fine_grained_embedding"
    sequence_length: 1024
    hidden_size: 768
    window_size: 32 # (32,32) = [B,32,H], (16,16) = [B,64,H], (8,8) = [B,128,H] (4,4) = [B,256,H]
    step_size: 16
  align:
    model_name: "MLP"
  # peft_config:
  #   type: "LORA"
  #   r: 16
  #   lora_alpha: 16
  #   lora_dropout: 0.1
  #   bias: "none"
  #   task_type: "CAUSAL_LM"
  #   modules_to_save: ['lm_head', 'embed_tokens']
  #   target_modules: ["q_proj", "v_proj", "k_proj","o_proj"]
  peft_config:
    type: "IA3"
    peft_type: "IA3"
    task_type: "CAUSAL_LM"
    target_modules: ["q_proj", "v_proj", "down_proj"]
    feedforward_modules: ["down_proj"]
  #peft_config:
  #    type: "PTUNING"
  #    task_type: "CAUSAL_LM"
  #    num_virtual_tokens: 20
  #    encoder_dropout: 0.1
  #    encoder_hidden_size: 4096
  # peft_config:
  #     type: "LLAMA-ADAPTER"
  #     task_type: "CAUSAL_LM"
  #     adapter_len: 10
  #     adapter_layers: 32


# lr from wavcaps, linear scale lr
optim_args:
  lr: 1e-4
  betas: [0.9, 0.99]
  eps: 1e-8
  momentum: 0.9
  gamma: 0.1
  weight_decay: 0.001

training:
  warmup_epochs: 2
  epochs: 10
  clip_grad: 2
  output_path: "./finetuned_models/frame2audio_MLP/"
  eval: True
  validate: False
  
index_args:
  #index_path: ""
  #index_path: "./data/index/final_index_big_kb/frame2frame_train.json"
  #index_path: "./data/index/final_index_big_kb/frame2frame_val.json"
  #index_path: "./data/index/final_index_big_kb/audio2text_train.json"
  index_path: "./data/index/final_index_big_kb/audio2text_val.json"
  #index_path: "./data/index/final_index_big_kb/audio2audio_train.json"
  #index_path: "./data/index/final_index_big_kb/audio2audio_val.json"
  top_k: 2
