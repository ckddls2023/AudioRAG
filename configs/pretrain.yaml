exp_name: 'pretrain'
seed: 20

train_jsons: [
  "data/json_files/AudioSet_SL/as_final.json",
  'data/json_files/AudioSet/train.json',
  'data/json_files/Clotho/train.json',
]
#train_jsons: [
#  'data/json_files/BBC_Sound_Effects/bbc_final.json',
#  'data/json_files/FreeSound/fsd_final.json',
#  'data/json_files/SoundBible/sb_final.json',
#  "data/json_files/AudioSet_SL/as_final.json",
#  #"data/json_files/Clotho/clotho_final.json"
#]
val_jsons: [
  "data/json_files/AudioSet/val.json",
]
blacklist: "data/json_files/blacklist/blacklist_exclude_test_ac.json"
# dataset == 'AudioCaps': sampling_rate = 32000
# dataset == 'Clotho': sampling_rate = 44100
# 48000 for CLAP
# 32000 for HTSAT
audio_args:
  sr: 48000
  n_fft: 1024
  hop_size: 320
  f_min: 50
  f_max: 14000
  n_mels: 64
  max_length: 10
  mono: True

data_args:
  dataset: "Clotho"
  global_batch_size: 256
  batch_size: 16
  num_workers: 16

model_args:
  name: "CLAP2LLAMA"
  freeze_am: True
  unfreeze_am: []
  freeze_lm: True
  checkpoint_path: "./pretrained_models/audio_caption_LGTM/"
  encoder:
    model_name: "CLAPAudioEncoder"
    pretrained: True
    freeze: True
    spec_augment: True
    select_feature: "fine_grained_embedding"
    sequence_length: 1024
    hidden_size: 768
    window_size: 8 # (32,32) = [B,32,H], (32,16) = [B,63,H] (16,16) = [B,64,H], (8,8) = [B,128,H] (4,4) = [B,256,H]
    step_size: 8
  align:
    model_name: "LGTM"


optim_args:
  lr: 1e-3
  betas: [0.9, 0.99]
  eps: 1e-8
  momentum: 0.9
  gamma: 0.1
  weight_decay: 0.0

training:
  warmup_epochs: 1
  epochs: 5
  clip_grad: 2
  output_path: "./pretrained_models/audio_caption_LGTM/"
  eval: False
  validate: False

index_args:
  index_path: "./data/index/final_index_big_kb/audio2audio_train.json"
  #index_path: "./data/index/final_index_big_kb/audio2audio_val.json"
  top_k: 2
